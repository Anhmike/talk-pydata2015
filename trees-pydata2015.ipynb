{
 "metadata": {
  "name": "",
  "signature": "sha256:be9d0153d82b2a2b6f31f821d95c76cec963b0c0defeefa93100d9fde2c323a2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Download original data from http://www3.dsi.uminho.pt/pcortez/wine/\n",
      "# Reference: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
      "#            \"Modeling wine preferences by data mining from physicochemical properties\". \n",
      "#            In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n",
      "\n",
      "# Load data\n",
      "red_wines = pd.read_csv(\"data/winequality-red.csv\", sep=\";\")\n",
      "white_wines = pd.read_csv(\"data/winequality-white.csv\", sep=\";\")\n",
      "wines = pd.concat((red_wines, white_wines))\n",
      "wines[\"color\"] = pd.Series(np.concatenate((np.zeros(len(red_wines)), \n",
      "                                           np.ones(len(white_wines)))))\n",
      "\n",
      "target = \"quality\"\n",
      "feature_names = wines.columns.drop(target).values\n",
      "X = wines.drop(target, axis=1).values\n",
      "y = wines[target].values\n",
      "\n",
      "print \"Features =\", feature_names\n",
      "print \"X =\", X\n",
      "print \"y =\", y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Features = ['fixed acidity' 'volatile acidity' 'citric acid' 'residual sugar'\n",
        " 'chlorides' 'free sulfur dioxide' 'total sulfur dioxide' 'density' 'pH'\n",
        " 'sulphates' 'alcohol' 'color']\n",
        "X = [[  7.4    0.7    0.   ...,   0.56   9.4    0.  ]\n",
        " [  7.8    0.88   0.   ...,   0.68   9.8    0.  ]\n",
        " [  7.8    0.76   0.04 ...,   0.65   9.8    0.  ]\n",
        " ..., \n",
        " [  6.5    0.24   0.19 ...,   0.46   9.4    1.  ]\n",
        " [  5.5    0.29   0.3  ...,   0.38  12.8    1.  ]\n",
        " [  6.     0.21   0.38 ...,   0.32  11.8    1.  ]]\n",
        "y = [5 5 5 ..., 6 7 6]\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.tree import DecisionTreeRegressor\n",
      "dt = DecisionTreeRegressor().fit(X_train, y_train)\n",
      "print dt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
        "           max_leaf_nodes=None, min_samples_leaf=1, min_samples_split=2,\n",
        "           min_weight_fraction_leaf=0.0, random_state=None,\n",
        "           splitter='best')\n"
       ]
      }
     ],
     "prompt_number": 36
    }
   ],
   "metadata": {}
  }
 ]
}